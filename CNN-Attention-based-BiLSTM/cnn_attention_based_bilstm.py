# -*- coding: utf-8 -*-
"""CNN-Attention-baseD- BiLSTM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xmNqTGd4sju8X0f2Jg8AIQGudPkDF055
"""

import wfdb
import numpy as np
import matplotlib.pyplot as plt
from scipy.signal import find_peaks
from collections import Counter
from google.colab import drive
import os
from tensorflow.keras.utils import to_categorical
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from tensorflow.keras.layers import Reshape
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense, Dropout, LSTM, Bidirectional, Conv1D, MaxPooling1D, Flatten, Reshape
from tensorflow.keras import backend as K
from tensorflow.keras.layers import Layer
from sklearn.metrics import classification_report, accuracy_score
from keras.regularizers import l2
from keras.optimizers import Adam
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

#Hyperparameter Tuned Model 2

#Attention Layer Logic
class Attention(Layer):
    def __init__(self, **kwargs):
        super(Attention, self).__init__(**kwargs)

    def build(self, input_shape):
        self.W = self.add_weight(name="att_weight", shape=(input_shape[-1], 1),
                                 initializer="normal")
        self.b = self.add_weight(name="att_bias", shape=(input_shape[1], 1),
                                 initializer="zeros")
        super(Attention, self).build(input_shape)

    def call(self, x):
        e = K.tanh(K.dot(x, self.W) + self.b)
        a = K.softmax(e, axis=1)
        output = x * a
        return K.sum(output, axis=1)

    def compute_output_shape(self, input_shape):
        return (input_shape[0], input_shape[-1])


# Define Input and Hyperparameters
input_layer = Input(shape=input_shape)
input_shape = (236, 1)
l2_reg = 0.01  # L2 regularization factor

# CNN layers with Max Pooling
conv1 = Conv1D(filters=32, kernel_size=5, activation='relu')(input_layer)
pool1 = MaxPooling1D(pool_size=2)(conv1)
conv2 = Conv1D(filters=64, kernel_size=5, activation='relu')(pool1)
pool2 = MaxPooling1D(pool_size=2)(conv2)

# Adjust the shape for the BiLSTM layer
reshape = Reshape((-1, 64))(pool2)

# BiLSTM layer
bi_lstm = Bidirectional(LSTM(64, return_sequences=True))(reshape)
attention = Attention()(bi_lstm)

# Flatten the output for the dense layers
flat = Flatten()(attention)

# Fully connected layers with L2 Regularization
dense1 = Dense(64, activation='relu', kernel_regularizer=l2(l2_reg))(flat)
output_layer = Dense(encoded_labels.shape[1], activation='softmax',kernel_regularizer=l2(l2_reg))(dense1)

# Model Compilation
optimizer = Adam(learning_rate=0.001)
cnn_bilstm_model2 = Model(inputs=input_layer, outputs=output_layer)
cnn_bilstm_model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Training the model
history3 = cnn_bilstm_model2.fit(X_train, y_train, epochs=20, batch_size=64, validation_split=0.2)

# Evaluate the model
test_loss, test_accuracy = cnn_bilstm_model2.evaluate(X_test, y_test)
print(f"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}")
print(f'L1 Regularization - Training Accuracy: {history3.history["accuracy"][-1]*100:.2f}%')
# Make predictions
predictions = cnn_bilstm_model2.predict(X_test)
predictions = np.argmax(predictions, axis=1)
y_true = np.argmax(y_test, axis=1)  # If y_test is one-hot encoded

# Calculate Accuracy
accuracy = accuracy_score(y_true, predictions)
unique_classes = np.unique(np.concatenate([y_true, predictions]))
# If using LabelEncoder, map class indices to class names
class_names = label_encoder.inverse_transform(unique_classes)
print("Accuracy After Hyper Parameter Tuning",accuracy)
# Generate the classification report
report = classification_report(y_true, predictions, labels=unique_classes, target_names=class_names)

# Print the classification report
print(report)

print(f'L2 Regularization - Testing Accuracy: {accuracy*100:.2f}%')
# Save the model
cnn_bilstm_att_model = 'cnn_bilstm_model2.h5'
cnn_bilstm_model2.save(cnn_bilstm_att_model)
print(f"Model saved as {cnn_bilstm_att_model}")

#plots

# Generate predictions
predictions = cnn_bilstm_model2.predict(X_test)
predicted_classes = np.argmax(predictions, axis=1)
true_classes = np.argmax(y_test, axis=1)

# Convert the one-hot encoded classes back to their original label encoding
true_labels = label_encoder.inverse_transform(true_classes)
predicted_labels = label_encoder.inverse_transform(predicted_classes)

# Calculate the confusion matrix
cm = confusion_matrix(true_labels, predicted_labels, labels=np.unique(true_labels))

# Normalize the confusion matrix to display percentages
cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100

# Plotting the normalized confusion matrix
plt.figure(figsize=(10, 7))
sns.heatmap(cm_percentage, annot=True, fmt='.2f', cmap='BuPu',
            xticklabels=np.unique(true_labels), yticklabels=np.unique(true_labels))

# Add titles and labels
plt.title('CNN - Attention-Based BiLSTM: Confusion Matrix')
plt.ylabel('Actual Classes')
plt.xlabel('Predicted Classes')

# Show the plot
plt.show()

from sklearn.metrics import roc_curve, auc, roc_auc_score
from sklearn.preprocessing import label_binarize
import numpy as np
import matplotlib.pyplot as plt
from itertools import cycle
from scipy import interp

# Your class labels (replace with your actual class labels)
class_labels = ['N', 'S', 'V', 'F', 'Q']  # Replace with your arrhythmia class labels

# Binarize the true classes for ROC curve calculation
y_test_binarized = label_binarize(true_classes, classes=np.arange(len(class_labels)))

# Compute ROC curve and ROC area for each class
fpr = dict()
tpr = dict()
roc_auc = dict()
n_classes = len(class_labels)

for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], predictions[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Compute macro-average ROC curve and ROC area
all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))
mean_tpr = np.zeros_like(all_fpr)
for i in range(n_classes):
    mean_tpr += interp(all_fpr, fpr[i], tpr[i])

mean_tpr /= n_classes
fpr["macro"] = all_fpr
tpr["macro"] = mean_tpr
roc_auc["macro"] = auc(fpr["macro"], tpr["macro"])

# Plot all ROC curves
plt.figure(figsize=(8, 6))

colors = cycle(['blue', 'red', 'green', 'orange', 'purple'])
for i, color in zip(range(n_classes), colors):
    plt.plot(fpr[i], tpr[i], color=color, lw=2,
             label='ROC curve of {0} (area = {1:0.2f})'.format(class_labels[i], roc_auc[i]))

plt.plot([0, 1], [0, 1], 'k--', lw=2)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('CNN - Attention-Based BiLSTM: Multi-Class ROC Analysis')
plt.legend(loc="lower right")
plt.show()

# Plot training & validation accuracy values
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(history3.history['accuracy'], color='blue', label='Train')
plt.plot(history3.history['val_accuracy'], color='red', label='Validation')
plt.title('Model Accuracy of CNN - Attention-Based BiLSTM')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(loc='upper left')

# Plot training & validation loss values
plt.subplot(1, 2, 2)
plt.plot(history3.history['loss'], color='green', label='Train')
plt.plot(history3.history['val_loss'], color='orange', label='Validation')
plt.title('Model Loss of CNN - Attention-Based BiLSTM')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(loc='upper right')

plt.show()