# -*- coding: utf-8 -*-
"""CNN_BILSTM_FULL_CODE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KzbLeJ3AwxmuMCV0A_I_OxWre3wUFhp8

#Prerequisites
"""

pip install wfdb
pip install scikit-learn

import wfdb
import numpy as np
import matplotlib.pyplot as plt
from scipy.signal import find_peaks
from collections import Counter
from google.colab import drive
import wfdb


import numpy as np
import os
from tensorflow.keras.utils import to_categorical
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from tensorflow.keras.layers import Reshape
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense, Dropout, LSTM, Bidirectional, Conv1D, MaxPooling1D, Flatten, Reshape
from tensorflow.keras import backend as K
from tensorflow.keras.layers import Layer
from sklearn.metrics import classification_report, accuracy_score

# Mount Google Drive
drive.mount('/content/gdrive')

# Path to the folder where your ECG files are stored in Google Drive
folder_path = '/content/gdrive/My Drive/Data 270 gwar/mitdb/'

"""# Preprocessing and Transformation"""

# Define the path to the ECG data files
folder_path = '/content/gdrive/My Drive/Data 270 gwar/mitdb/'

# Define the Butterworth filter
def butter_lowpass(cutoff, fs, order=5):
    nyq = 0.5 * fs
    normal_cutoff = cutoff / nyq
    b, a = butter(order, normal_cutoff, btype='low', analog=False)
    return b, a

def butter_lowpass_filter(data, cutoff, fs, order=5):
    b, a = butter_lowpass(cutoff, fs, order=order)
    y = lfilter(b, a, data)
    return y
# Change directory to the folder where ECG data is stored
os.chdir(folder_path)

# Parameters for the Butterworth filter
cutoff_frequency = 0.1  # Define an appropriate cutoff frequency
sampling_rate = 360  # Define the sampling rate of the ECG data
filter_order = 5  # Define the order of the filter

# AAMI heartbeat classification mapping based on MIT-BIH annotations
aami_mapping = {
    'N': 'N', 'L': 'N', 'R': 'N', 'e': 'N', 'j': 'N',  # Non-ectopic beats
    'A': 'S', 'a': 'S', 'J': 'S', 'S': 'S',             # Supraventricular ectopic beats
    'V': 'V', 'E': 'V', '!': 'V', '[': 'V', ']': 'V',   # Ventricular ectopic beats
    'F': 'F',                                           # Fusion beats
    '/': 'Q', 'f': 'Q', 'Q': 'Q'                        # Unknown beats
}

# Initialize lists to store processed data
all_heartbeats = []
all_labels = []

# Define the file IDs for records to process
file_ids = [str(x) for x in [100, 101, 102, 103, 104, 105, 106, 107, 108, 109,
                             111, 112, 113, 114, 115, 116, 117, 118, 119,
                             121, 122, 123, 124,
                             200, 201, 202, 203, 205, 207, 208, 209, 210,
                             212, 213, 214, 215, 217, 219, 220, 221, 222, 223, 228, 230, 231, 232, 233, 234]]

# Process each ECG record
for file_id in file_ids:
    record_name = os.path.join(folder_path, file_id)
    try:
        # Load ECG data and annotations
        signals, fields = wfdb.rdsamp(record_name, sampfrom=0, channels=[0])
        annotation = wfdb.rdann(record_name, 'atr')

        # Find R-peaks in the ECG signal (assuming normal ECG signal without filtering)
        r_peaks, _ = find_peaks(signals[:, 0], distance=fields['fs']*0.6)

        # Extract heartbeats based on R-peaks
        for r_peak in r_peaks:
            start, end = r_peak - 128, r_peak + 108
            if start >= 0 and end <= len(signals):
                heartbeat = signals[start:end, 0]
                all_heartbeats.append(heartbeat)

                # Find the closest annotation to the R-peak
                annotation_index = np.argmin(np.abs(annotation.sample - r_peak))
                symbol = annotation.symbol[annotation_index]
                all_labels.append(symbol)

    except FileNotFoundError:
        print(f"File '{record_name}' not found. Skipping...")

# Map the annotations to AAMI classes and count them
aami_label_counts = Counter()
for symbol in all_labels:
    if symbol in aami_mapping:
        aami_class = aami_mapping[symbol]
        aami_label_counts[aami_class] += 1

# Print the count for each AAMI class
print("AAMI Label Counts after categorization:")
for aami_class, count in aami_label_counts.items():
    print(f"{aami_class}: {count}")

# Print the total number of heartbeats categorized
print(f"Total number of heartbeats categorized: {len(all_heartbeats)}")

# Print the count for each AAMI class
print("AAMI Label Counts after categorization:")
for aami_class, count in aami_label_counts.items():
    print(f"{aami_class}: {count}")

# Calculate the total number of heartbeats and labels
total_heartbeats = len(all_heartbeats)
total_labels = len(all_labels)  # This is before filtering unmapped annotations

# Print the total number of heartbeats and labels
print(f"Total number of heartbeats: {total_heartbeats}")
print(f"Total number of labels: {total_labels}")

# If you also want to print the total number of mapped labels after AAMI categorization
mapped_labels_count = sum(aami_label_counts.values())
print(f"Total number of mapped labels after AAMI categorization: {mapped_labels_count}")

# Print the count for each AAMI class
print("AAMI Label Counts after categorization:")
for aami_class, count in aami_label_counts.items():
    print(f"{aami_class}: {count}")

# Filter out heartbeats that correspond to unmapped labels
mapped_heartbeats = [hb for hb, lbl in zip(all_heartbeats, all_labels) if lbl in aami_mapping]

# Calculate the total number of mapped heartbeats after AAMI categorization
total_mapped_heartbeats = len(mapped_heartbeats)

# Calculate the total number of mapped labels after AAMI categorization
total_mapped_labels = sum(aami_label_counts.values())

# Print the total number of mapped heartbeats and mapped labels
print(f"Total number of mapped heartbeats after AAMI categorization: {total_mapped_heartbeats}")
print(f"Total number of mapped labels after AAMI categorization: {total_mapped_labels}")

# Filter and map the labels to AAMI categories
mapped_labels = []
mapped_heartbeats = []

for symbol, heartbeat in zip(all_labels, all_heartbeats):
    if symbol in aami_mapping:
        aami_class = aami_mapping[symbol]
        mapped_labels.append(aami_class)
        mapped_heartbeats.append(heartbeat)

# Now, mapped_heartbeats contains heartbeats that have corresponding AAMI labels
# And mapped_labels contains the AAMI labels for these heartbeats

# Print the total number of mapped heartbeats and mapped labels after AAMI categorization
print(f"Total number of mapped heartbeats after AAMI categorization: {len(mapped_heartbeats)}")
print(f"Total number of mapped labels after AAMI categorization: {len(mapped_labels)}")

# Ensure all heartbeats are of equal length
heartbeat_length = 236
all_heartbeats = [hb for hb in mapped_heartbeats if len(hb) == heartbeat_length]

# Normalize the data (if necessary)
# Example: Standardize each heartbeat
mapped_heartbeats = np.array(mapped_heartbeats)
mapped_heartbeats = (mapped_heartbeats - np.mean(mapped_heartbeats, axis=1, keepdims=True)) / np.std(mapped_heartbeats, axis=1, keepdims=True)

# Encode the labels
label_encoder = LabelEncoder()
encoded_labels = label_encoder.fit_transform(mapped_labels)
encoded_labels = to_categorical(encoded_labels)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(mapped_heartbeats, encoded_labels, test_size=0.2, random_state=42)

"""# Attention Mechanism"""

class Attention(Layer):
    def __init__(self, **kwargs):
        super(Attention, self).__init__(**kwargs)

    def build(self, input_shape):
        self.W = self.add_weight(name="att_weight", shape=(input_shape[-1], 1),
                                 initializer="normal")
        self.b = self.add_weight(name="att_bias", shape=(input_shape[1], 1),
                                 initializer="zeros")
        super(Attention, self).build(input_shape)

    def call(self, x):
        e = K.tanh(K.dot(x, self.W) + self.b)
        a = K.softmax(e, axis=1)
        output = x * a
        return K.sum(output, axis=1)

    def compute_output_shape(self, input_shape):
        return (input_shape[0], input_shape[-1])

"""# Base Model"""

#Initial Model
input_shape = (236, 1)
# Model architecture
input_layer = Input(shape=input_shape)

# CNN layers
conv1 = Conv1D(filters=32, kernel_size=5, activation='relu')(input_layer)
pool1 = MaxPooling1D(pool_size=2)(conv1)
conv2 = Conv1D(filters=64, kernel_size=5, activation='relu')(pool1)
pool2 = MaxPooling1D(pool_size=2)(conv2)

# Adjust the shape for the BiLSTM layer
# This assumes the output of pool2 has shape (None, timesteps, features)
reshape = Reshape((-1, 64))(pool2)  # Adjust '64' based on the shape of pool2

# BiLSTM layer
bi_lstm = Bidirectional(LSTM(64, return_sequences=True))(reshape)
attention = Attention()(bi_lstm)

# Flatten the output for the dense layers
flat = Flatten()(attention)

# Fully connected layers
dense1 = Dense(64, activation='relu')(flat)

output_layer = Dense(encoded_labels.shape[1], activation='softmax')(dense1)

# Compile the model
model = Model(inputs=input_layer, outputs=output_layer)
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Model summary
model.summary()

final_layer = model.layers[-1]  # Accessing the last layer
print("Number of output units (classes):", final_layer.units)
input_layer = model.layers[0]  # Accessing the first layer
print("Model input shape:", input_layer.input_shape)

"""# Base Model Training"""

# Training the model
history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)

# Evaluate the model
test_loss, test_accuracy = model.evaluate(X_test, y_test)
print(f"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}")

"""# Base Model Testing"""

# Make predictions
predictions = model.predict(X_test)
predictions = np.argmax(predictions, axis=1)
y_true = np.argmax(y_test, axis=1)  # If y_test is one-hot encoded

# Calculate Accuracy
accuracy = accuracy_score(y_true, predictions)
unique_classes = np.unique(np.concatenate([y_true, predictions]))
# If using LabelEncoder, map class indices to class names
class_names = label_encoder.inverse_transform(unique_classes)
print("Accuracy Before Hyper Parameter Tuning",accuracy)
# Generate the classification report
report = classification_report(y_true, predictions, labels=unique_classes, target_names=class_names)

# Print the classification report
print(report)

import numpy as np
from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,
                             confusion_matrix, classification_report, roc_auc_score,
                             average_precision_score, cohen_kappa_score, matthews_corrcoef,
                             log_loss)
from tensorflow.keras.models import load_model

# Load your trained model
# model = load_model('your_model_path.h5')

# Make predictions on the test set
y_pred_proba = model.predict(X_test)  # Probabilistic predictions
y_pred = np.argmax(y_pred_proba, axis=1)
y_true = np.argmax(y_test, axis=1)  # Assuming y_test is one-hot encoded

# Basic Metrics
accuracy = accuracy_score(y_true, y_pred)
precision = precision_score(y_true, y_pred, average='weighted')
recall = recall_score(y_true, y_pred, average='weighted')
f1 = f1_score(y_true, y_pred, average='weighted')
conf_matrix = confusion_matrix(y_true, y_pred)
class_report = classification_report(y_true, y_pred)

# Advanced Metrics (Some of these might not apply for multi-class classification)
roc_auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr')  # For binary classification, remove 'multi_class' parameter
average_precision = average_precision_score(y_test, y_pred_proba, average='weighted')
kappa = cohen_kappa_score(y_true, y_pred)
mcc = matthews_corrcoef(y_true, y_pred)
cross_entropy_loss = log_loss(y_test, y_pred_proba)

# Print metrics
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1)
print("Confusion Matrix:\n", conf_matrix)
print("Classification Report:\n", class_report)
print("ROC AUC:", roc_auc)
print("Average Precision:", average_precision)
print("Cohen's Kappa:", kappa)
print("Matthews Correlation Coefficient:", mcc)
print("Log Loss (Cross-Entropy Loss):", cross_entropy_loss)
print("Test Accuracy:", accuracy)

"""# Hyperparameter tuned model 1"""

# with l1 regularization and leraning rate for Adam optimizer
from keras.layers import Input, Conv1D, MaxPooling1D, Bidirectional, LSTM, Dense, Dropout, Flatten, Reshape
from keras.models import Model
from keras.regularizers import l1
from keras.optimizers import Adam

input_shape = (236, 1)
l1_reg = 0.01  # L1 regularization factor, similar to Lasso's alpha

# Model architecture
input_layer = Input(shape=input_shape)

# CNN layers
conv1 = Conv1D(filters=32, kernel_size=5, activation='relu')(input_layer)
pool1 = MaxPooling1D(pool_size=2)(conv1)
conv2 = Conv1D(filters=64, kernel_size=5, activation='relu')(pool1)
pool2 = MaxPooling1D(pool_size=2)(conv2)

# Adjust the shape for the BiLSTM layer
reshape = Reshape((-1, 64))(pool2)

# BiLSTM layer
bi_lstm = Bidirectional(LSTM(64, return_sequences=True))(reshape)
attention = Attention()(bi_lstm)

# Flatten the output for the dense layers
flat = Flatten()(attention)

# Fully connected layers with L1 Regularization (Lasso-style)
dense1 = Dense(64, activation='relu', kernel_regularizer=l1(l1_reg))(flat)
#dropout = Dropout(0.5)(dense1)
output_layer = Dense(encoded_labels.shape[1], activation='softmax')(dense1)

# Compile the model
#  # Adjust learning rate as needed
cnn_bilstm_model1 = Model(inputs=input_layer, outputs=output_layer)
cnn_bilstm_model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Training the model
history2 = cnn_bilstm_model1.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)

# Evaluate the model
test_loss, test_accuracy = cnn_bilstm_model1.evaluate(X_test, y_test)
print(f"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}")
print(f'L1 Regularization - Training Accuracy: {history2.history["accuracy"][-1]*100:.2f}%')
# Make predictions
predictions = cnn_bilstm_model1.predict(X_test)
predictions = np.argmax(predictions, axis=1)
y_true = np.argmax(y_test, axis=1)  # If y_test is one-hot encoded

# Calculate Accuracy
accuracy = accuracy_score(y_true, predictions)
unique_classes = np.unique(np.concatenate([y_true, predictions]))
# If using LabelEncoder, map class indices to class names
class_names = label_encoder.inverse_transform(unique_classes)
print("Accuracy After Hyper Parameter Tuning",accuracy)
# Generate the classification report
report = classification_report(y_true, predictions, labels=unique_classes, target_names=class_names)

# Print the classification report
print(report)

print(f'L1 Regularization - Testing Accuracy: {accuracy*100:.2f}%')

import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, accuracy_score
import seaborn as sns
import numpy as np
from sklearn.preprocessing import label_binarize
from sklearn.metrics import ConfusionMatrixDisplay

# Confusion Matrix
cm = confusion_matrix(y_true, predictions)
plt.figure(figsize=(10,7))
sns.heatmap(cm, annot=True, fmt="d", cmap='BuPu', xticklabels=class_names, yticklabels=class_names)
plt.title('Confusion Matrix')
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show()

# ROC/AUC Curve
y_test_binarized = label_binarize(y_test, classes=unique_classes)
predictions_binarized = label_binarize(predictions, classes=unique_classes)
fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(len(class_names)):
    fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], predictions_binarized[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])
    plt.plot(fpr[i], tpr[i], label=f'ROC curve (area = {roc_auc[i]:.2f}) for class {class_names[i]}')

plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curves')
plt.legend(loc="lower right")
plt.show()

# Training and Validation Loss and Accuracy Curves
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.plot(history2.history['loss'], label='Training Loss')
plt.plot(history2.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history2.history['accuracy'], label='Training Accuracy')
plt.plot(history2.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.legend()

plt.show()

"""# Hyperparameter tuned model 2"""

#Hyperparameter Tuned Model 2
from keras.layers import Input, Conv1D, MaxPooling1D, Bidirectional, LSTM, Dense, Flatten, Reshape
from keras.models import Model
from keras.regularizers import l2  # Import L2 regularization
from keras.optimizers import Adam
from tensorflow.keras.layers import Reshape
from tensorflow.keras.models import Model
from tensorflow.keras import backend as K
from tensorflow.keras.layers import Layer

#Attention Layer Logic
class Attention(Layer):
    def __init__(self, **kwargs):
        super(Attention, self).__init__(**kwargs)

    def build(self, input_shape):
        self.W = self.add_weight(name="att_weight", shape=(input_shape[-1], 1),
                                 initializer="normal")
        self.b = self.add_weight(name="att_bias", shape=(input_shape[1], 1),
                                 initializer="zeros")
        super(Attention, self).build(input_shape)

    def call(self, x):
        e = K.tanh(K.dot(x, self.W) + self.b)
        a = K.softmax(e, axis=1)
        output = x * a
        return K.sum(output, axis=1)

    def compute_output_shape(self, input_shape):
        return (input_shape[0], input_shape[-1])


# Define Input and Hyperparameters
input_layer = Input(shape=input_shape)
input_shape = (236, 1)
l2_reg = 0.01  # L2 regularization factor

# CNN layers with Max Pooling
conv1 = Conv1D(filters=32, kernel_size=5, activation='relu')(input_layer)
pool1 = MaxPooling1D(pool_size=2)(conv1)
conv2 = Conv1D(filters=64, kernel_size=5, activation='relu')(pool1)
pool2 = MaxPooling1D(pool_size=2)(conv2)

# Adjust the shape for the BiLSTM layer
reshape = Reshape((-1, 64))(pool2)

# BiLSTM layer
bi_lstm = Bidirectional(LSTM(64, return_sequences=True))(reshape)
attention = Attention()(bi_lstm)

# Flatten the output for the dense layers
flat = Flatten()(attention)

# Fully connected layers with L2 Regularization
dense1 = Dense(64, activation='relu', kernel_regularizer=l2(l2_reg))(flat)
output_layer = Dense(encoded_labels.shape[1], activation='softmax',kernel_regularizer=l2(l2_reg))(dense1)

# Model Compilation
optimizer = Adam(learning_rate=0.001)
cnn_bilstm_model2 = Model(inputs=input_layer, outputs=output_layer)
cnn_bilstm_model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
cnn_bilstm_model2.summary()

# Training the model
history3 = cnn_bilstm_model2.fit(X_train, y_train, epochs=20, batch_size=64, validation_split=0.2)

# Evaluate the model
test_loss, test_accuracy = cnn_bilstm_model2.evaluate(X_test, y_test)
print(f"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}")
print(f'L1 Regularization - Training Accuracy: {history3.history["accuracy"][-1]*100:.2f}%')
# Make predictions
predictions = cnn_bilstm_model2.predict(X_test)
predictions = np.argmax(predictions, axis=1)
y_true = np.argmax(y_test, axis=1)  # If y_test is one-hot encoded

# Calculate Accuracy
accuracy = accuracy_score(y_true, predictions)
unique_classes = np.unique(np.concatenate([y_true, predictions]))
# If using LabelEncoder, map class indices to class names
class_names = label_encoder.inverse_transform(unique_classes)
print("Accuracy After Hyper Parameter Tuning",accuracy)
# Generate the classification report
report = classification_report(y_true, predictions, labels=unique_classes, target_names=class_names)

# Print the classification report
print(report)

print(f'L2 Regularization - Testing Accuracy: {accuracy*100:.2f}%')
# Save the model
cnn_bilstm_att_model = 'cnn_bilstm_model2.h5'
cnn_bilstm_model2.save(cnn_bilstm_att_model)
print(f"Model saved as {cnn_bilstm_att_model}")


#plots
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt


# Generate predictions
predictions = cnn_bilstm_model2.predict(X_test)
predicted_classes = np.argmax(predictions, axis=1)
true_classes = np.argmax(y_test, axis=1)

# Convert the one-hot encoded classes back to their original label encoding
true_labels = label_encoder.inverse_transform(true_classes)
predicted_labels = label_encoder.inverse_transform(predicted_classes)

# Calculate the confusion matrix
cm = confusion_matrix(true_labels, predicted_labels, labels=np.unique(true_labels))

# Normalize the confusion matrix to display percentages
cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100

# Plotting the normalized confusion matrix
plt.figure(figsize=(10, 7))
sns.heatmap(cm_percentage, annot=True, fmt='.2f', cmap='BuPu',
            xticklabels=np.unique(true_labels), yticklabels=np.unique(true_labels))

# Add titles and labels
plt.title('CNN - Attention-Based BiLSTM: Confusion Matrix')
plt.ylabel('Actual Classes')
plt.xlabel('Predicted Classes')

# Show the plot
plt.show()

from sklearn.metrics import roc_curve, auc, roc_auc_score
from sklearn.preprocessing import label_binarize
import numpy as np
import matplotlib.pyplot as plt
from itertools import cycle
from scipy import interp

# Your class labels (replace with your actual class labels)
class_labels = ['N', 'S', 'V', 'F', 'Q']  # Replace with your arrhythmia class labels

# Binarize the true classes for ROC curve calculation
y_test_binarized = label_binarize(true_classes, classes=np.arange(len(class_labels)))

# Compute ROC curve and ROC area for each class
fpr = dict()
tpr = dict()
roc_auc = dict()
n_classes = len(class_labels)

for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], predictions[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Compute macro-average ROC curve and ROC area
all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))
mean_tpr = np.zeros_like(all_fpr)
for i in range(n_classes):
    mean_tpr += interp(all_fpr, fpr[i], tpr[i])

mean_tpr /= n_classes
fpr["macro"] = all_fpr
tpr["macro"] = mean_tpr
roc_auc["macro"] = auc(fpr["macro"], tpr["macro"])

# Plot all ROC curves
plt.figure(figsize=(8, 6))

colors = cycle(['blue', 'red', 'green', 'orange', 'purple'])
for i, color in zip(range(n_classes), colors):
    plt.plot(fpr[i], tpr[i], color=color, lw=2,
             label='ROC curve of {0} (area = {1:0.2f})'.format(class_labels[i], roc_auc[i]))

plt.plot([0, 1], [0, 1], 'k--', lw=2)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('CNN - Attention-Based BiLSTM: Multi-Class ROC Analysis')
plt.legend(loc="lower right")
plt.show()

# Plot training & validation accuracy values
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(history3.history['accuracy'], color='blue', label='Train')
plt.plot(history3.history['val_accuracy'], color='red', label='Validation')
plt.title('Model Accuracy of CNN - Attention-Based BiLSTM')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(loc='upper left')

# Plot training & validation loss values
plt.subplot(1, 2, 2)
plt.plot(history3.history['loss'], color='green', label='Train')
plt.plot(history3.history['val_loss'], color='orange', label='Validation')
plt.title('Model Loss of CNN - Attention-Based BiLSTM')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(loc='upper right')

plt.show()